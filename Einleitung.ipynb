{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyOMe4y0y6N2y+sHmBrc4Uf/"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ziele\n",
    "\n",
    "Im Rahmen unserer Projektarbeit für Learning und Softcomputing haben wir uns mit einer Sentiment-Analyse von zwei verschiedenen Datenquellen beschäftig.\n",
    "\n",
    "Unsere selbstgestecken Ziele für die Projektarbeit lassen sich wie folgt zusammenfassen:\n",
    "- Wir wollten verschiedene NLP-Ansätze ausprobieren, um die Sentiment-Klassen der Daten vorherzusagen. Dabei haben wir uns vorgenommen verschiedene klassische Machine Learning-Ansätze ohne Deep Learning sowie einen Deep Learning-Ansatz auszuprobieren und mit einander zu vergleichen.\n",
    "- Im Rahmen der verschiedene Techniken war außerdem, besonders bei dem Deep Learning-Ansatz, die Auswirkung von unterschiedlichen Hyperparameter zu evaluieren.\n",
    "- Neben der Variation an Verfahren haben wir zwei unterschiedliche Datensätze (Movie Reviews und Tweets) mit den gleichen Techniken bearbeitet und auch diese Ergebnisse miteinander vergleichen.\n",
    "- Neben der inhaltlichen Evaluation war ein weiteres wichtiges Ziel für uns, viel praktische Erfahrung im Bezug auf das methodische Vorgehen bei solchen Data Science Projekten zu sammeln."
   ],
   "metadata": {
    "id": "lzQTJxz25Oe5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aufbau der Projektdokumentation\n",
    "\n",
    "Da im Rahmen der Projektarbeit eine Menge an Code entstanden ist, haben wir uns für eine gemischte Nutzung von Colab Notebooks und normalen Python Sktipten entschieden. Gerade bei dem Training der Neuronalen Netze haben wir einige Klassen geschrieben, die wir nur in Notebooks importieren, um Sie dann auf Colab auszuführen.\n",
    "\n",
    "Der relevante Ergebnisteil des Projektarbeit ist jedoch komplett in Notebooks verfasst. Dazu haben wir im Ordner 'Notebooks' 3 relevante Notebooks angelegt. Wir empfehlen zur Nachverfolgung unseres Projektes dabei diese Reihenfolge:\n",
    "1. *ExploratoryDataAnalysis.ipynb*: Hier werden die beiden genannten Datensätze explorativ untersucht und einen Teil des Preprocessing erledigt\n",
    "2. *Project_BoW.ipynb*: ######\n",
    "3. *summary_BERT.ipynb*: In diesem Notebook sind das gesamte Vorgehen beim Training von Neuronalen Netzen sowie die Ergebnisse zusammengefasst und präsentiert"
   ],
   "metadata": {
    "id": "zdZKyIWJ7zcD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gesamtfazit\n",
    "\n",
    "In den Notebook 2. und 3. finden sich jeweils spezifische Fazits zu den einzelnen Techniken. Im Hinblick auf die oben genannten Ziele können wir hier aber folgende übergreifenden Erkenntnisse zusammenfassen:\n",
    "- Im Vergleich zu den klassischen Ansätze ist der Deep Learning-Ansatz mit der Datenmenge und der Rechenleistung, die uns für dieses Projekt zur Verfügung stand nicht deutlich besser. Nur mit einem Trick (Early Stopping) konnte auf dem Movie Review-Datensatz eine Accuracy von 0.06 besser erreicht werden.\n",
    "- Bei beiden Ansätzen ist die Performance bei dem Tweets-Datensatz deutlich höher. Dies kann an der reduzierten Klassenanzahl, an dem deutlich größeren Umfang des Datensatzes oder an der Domäne liegen.\n",
    "- Im Vergleich bzgl. der Übertragbarkeit zwischen den Domänen zeigt sich ein gemischtes Bild. Bei den Modellen, die auf dem Movie Review-Datensatz trainiert wurden, sind die klassischen Modelle etwas besser übertragbar auf den anderen Datensatz. Bei dem Tweets-Modellen liegt das Deep Learning-Ansatz ein wenig vorne.\n",
    "- Bei kleinen Datensätzen lohnt es sich immer zunächst einfache/klassische Modell auszuprobieren, weil Deep Learning-Modell mehr Aufwand bedeuten, mehr Rechenkapazität benötigen und mehr Daten benötigen, um gut lernen zu können.\n",
    "- Beim Training von Neuronalen Netzen ist es sinnvoll sich vorher alle möglichen Trainingsvarianten zu überlegen im Hinblick auf das Datenformat, das Preprocessing oder das Hyperparametertuning, um von Anfang an eine sinnvolle Programmstruktur zu nutzen.\n",
    "- Das Vergleichen von verschiedenen Klassifizierungsmodellen funktioniert nur sehr bedingt, wenn die Modell und die entsprechenden Trainingsdaten eine unterschiedliche Anzahl an Klassen haben. Obwohl die Klassen bei uns Ordinal bis anähernt Metrisch sind hat die Vergleichbarkeit darunter gelitten. Hauptursache ist unserer Einschätzung nach, dass die eine Skala einen Mittelpunkt hat (neutral), die andere aber nicht."
   ],
   "metadata": {
    "id": "l5564Uni-FTc"
   }
  }
 ]
}
