{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentenceId  PhraseId                                             Phrase  \\\n",
       "0           1         1  A series of escapades demonstrating the adage ...   \n",
       "1           2        64  This quiet , introspective and entertaining in...   \n",
       "2           3        82  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "3           4       117  A positively thrilling combination of ethnogra...   \n",
       "4           5       157  Aggressive self-glorification and a manipulati...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          4  \n",
       "2          1  \n",
       "3          3  \n",
       "4          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "data = pd.read_csv (\"train.tsv\", sep = '\\t')\n",
    "\n",
    "# Teilsätze rausschmeißen\n",
    "data = data.groupby('SentenceId').first().reset_index()\n",
    "data.head()\n",
    "\n",
    "\n",
    "# so Daten laden, wenn das test_set Sentiment Labels hätte:\n",
    "#train_set = pd.read_csv (\"train.tsv\", sep = '\\t')\n",
    "#test_set= pd.read_csv (\"test.tsv\", sep = '\\t')\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "#test_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2321\n",
       "1    2200\n",
       "2    1655\n",
       "4    1281\n",
       "0    1072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sentiment.value_counts()\n",
    "\n",
    "# Daten ausbalancieren im Trainings-Set? \n",
    "# Jeder Sentiment Value sollte gleiche Anzahl an Samples haben "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# pip install nltk\n",
    "import re\n",
    "\n",
    "\n",
    "# Für Sentimentanalyse zählen nur Wörter  \n",
    "def keep_only_letters(text):\n",
    "    text=re.sub(r'[^a-zA-Z\\s]','',text)\n",
    "    return text\n",
    " \n",
    "# Groß- und Kleinschreibung egal \n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    " \n",
    "def clean_reviews(text):\n",
    "    text = keep_only_letters(text)\n",
    "    text = convert_to_lowercase(text)\n",
    "    return text\n",
    "\n",
    "data['Phrase'] = data['Phrase'].apply(clean_reviews)\n",
    "# train_set['Phrase'] = train_set['Phrase'].apply(clean_reviews)\n",
    "# test_set['Phrase'] = test_set['Phrase'].apply(clean_reviews)\n",
    "\n",
    "# Stop Words definition\n",
    "english_stop_words = nltk.corpus.stopwords.words('english')\n",
    "print(len(english_stop_words))\n",
    "print (english_stop_words[:20])\n",
    "\n",
    "# Stop Words removal\n",
    "def remove_stop_words(text):\n",
    "    for stopword in english_stop_words:\n",
    "        stopword = ' ' + stopword + ' '\n",
    "        text = text.replace(stopword, ' ')\n",
    "    return text\n",
    " \n",
    "\n",
    "data['Phrase'] = data['Phrase'].apply(remove_stop_words) \n",
    "#train_set['Phrase'] = train_set['Phrase'].apply(remove_stop_words)\n",
    "#test_set['Phrase'] = test_set['Phrase'].apply(remove_stop_words)\n",
    "\n",
    "\n",
    "# Stemming\n",
    "def text_stemming(text):\n",
    "    stemmer = nltk.porter.PorterStemmer()\n",
    "    stemmed = ' '.join([stemmer.stem(token) for token in text.split()])\n",
    "    return stemmed\n",
    "\n",
    "data['Phrase'] = data['Phrase'].apply(text_stemming) \n",
    "#train_set['Phrase'] = train_set['Phrase'].apply(text_stemming)\n",
    "#test_set['Phrase'] = test_set['Phrase'].apply(text_stemming)\n",
    "\n",
    "#train_set.head(10)\n",
    "#train_set.shape\n",
    "#test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Vectorization\n",
    "CountVectorizer aus sklearn um bag-of-words Darstellung von unserem Trainings- und Testset zu erhalten\n",
    "naive bag-of-words text vectorization\n",
    "\n",
    "Nur Trainingsdatensatz zur Definition des Vokabulars heranziehen und \n",
    "das gleiche Vokabular zur Darstellung des Test-Datensatzes verwenden\n",
    "-> Vektorizer an Trainingsdaten anpassen und zur Transformation der Testdaten verwenden\n",
    "\n",
    "weighted version of BOW ausprobieren?\n",
    "\n",
    "### N-Grams\n",
    "\n",
    "Unigramme: Alle eindeutigen Wörter in einem Dokument\n",
    "\n",
    "BiGramme: Alle Permutationen von zwei aufeinanderfolgenden Wörtern in einem Dokument\n",
    "\n",
    "TriGrams: Alle Permutationen von drei aufeinanderfolgenden Wörtern in einem Dokument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "# Argument binary=False: Vocabel-Vector mit term-frequency füllen\n",
    "# binary = True: Vocabel-Vector mit Vorhandensein der Token füllen (1 vorhanden, 0 nicht vorhanden) \n",
    "# ngram _range = Unigram: (1,1); Bigram: (1,2); Trigram: (1,3)\n",
    "\n",
    "vectorizer_uni = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,1))\n",
    "vectorizer_bi = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,2))\n",
    "vectorizer_tri = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,3))\n",
    "\n",
    "uni_features_train = vectorizer_uni.fit_transform(train_set['Phrase'])\n",
    "uni_features_test = vectorizer_uni.transform(test_set['Phrase'])\n",
    "#print (uni_features_train.shape, uni_features_test.shape)\n",
    "\n",
    "bi_features_train = vectorizer_bi.fit_transform(train_set['Phrase'])\n",
    "bi_features_test = vectorizer_bi.transform(test_set['Phrase'])\n",
    "#print (bi_features_train.shape, bi_features_test.shape)\n",
    "\n",
    "tri_features_train = vectorizer_tri.fit_transform(train_set['Phrase'])\n",
    "tri_features_test = vectorizer_tri.transform(test_set['Phrase'])\n",
    "#print (tri_features_train.shape, tri_features_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram:\n",
    "(156060, 10998) (66292, 10998): 10998 einzigartige englische token in unserem Vokabular (abgeleitet aus Trainingsdatensatz)\n",
    "Jeder Token wird durch eine Spalte im Datensatz repräsentiert\n",
    "Für jedes Review im Datensatz wird die Frequency der Token (term-frequency) durch Vokabel-Vector der Größe 10998 dargestellt.\n",
    "= Daher haben wir 156060 solcher Vektoren in unserem Trainings-Datensatz und 66292 in unserem Test-Datensatz = Anzahl der Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_set['Sentiment']\n",
    "test_labels = test_set['Sentiment']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Klassifizierungsmodelle trainieren\n",
    "### 4.1.  Naive Bayes\n",
    "#### 4.1.1. Unigram (Logistic Regression classifier on unigram features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.11      0.17       238\n",
      "           1       0.38      0.57      0.46       418\n",
      "           2       0.31      0.16      0.21       334\n",
      "           3       0.40      0.59      0.48       485\n",
      "           4       0.41      0.25      0.31       231\n",
      "\n",
      "    accuracy                           0.39      1706\n",
      "   macro avg       0.38      0.34      0.33      1706\n",
      "weighted avg       0.38      0.39      0.36      1706\n",
      "\n",
      "[[ 25 143  25  43   2]\n",
      " [ 22 240  34 109  13]\n",
      " [  8 121  53 134  18]\n",
      " [  5  96  49 285  50]\n",
      " [  0  31   9 133  58]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    " \n",
    "vectorizer_uni = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,1))\n",
    "uni_features_train = vectorizer_uni.fit_transform(train_set['Phrase'])\n",
    "uni_features_test = vectorizer_uni.transform(test_set['Phrase'])\n",
    "\n",
    "uni_nb = MultinomialNB()\n",
    "uni_nb.fit(uni_features_train, train_labels)\n",
    " \n",
    "predictions = uni_nb.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','1','2','3','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 1, 2, 3, 4]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Naive Bayes: Unigram + Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.07      0.12       238\n",
      "           1       0.38      0.63      0.47       418\n",
      "           2       0.31      0.10      0.15       334\n",
      "           3       0.40      0.67      0.50       485\n",
      "           4       0.45      0.13      0.20       231\n",
      "\n",
      "    accuracy                           0.39      1706\n",
      "   macro avg       0.41      0.32      0.29      1706\n",
      "weighted avg       0.40      0.39      0.33      1706\n",
      "\n",
      "[[ 16 157  19  44   2]\n",
      " [ 11 263  21 118   5]\n",
      " [  3 133  32 160   6]\n",
      " [  2 108  26 325  24]\n",
      " [  0  30   5 166  30]]\n"
     ]
    }
   ],
   "source": [
    "#vectorizer_bi = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,2))\n",
    "#bi_features_train = vectorizer_bi.fit_transform(train_set['Phrase'])\n",
    "#bi_features_test = vectorizer_bi.transform(test_set['Phrase'])\n",
    "\n",
    "bi_nb = MultinomialNB()\n",
    "bi_nb.fit(bi_features_train, train_labels)\n",
    " \n",
    "predictions = bi_nb.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','1','2','3','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 1, 2, 3, 4]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Naive Bayes: Unigram + Bigram + Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.05      0.10       238\n",
      "           1       0.38      0.64      0.48       418\n",
      "           2       0.34      0.09      0.14       334\n",
      "           3       0.40      0.69      0.51       485\n",
      "           4       0.46      0.11      0.18       231\n",
      "\n",
      "    accuracy                           0.39      1706\n",
      "   macro avg       0.42      0.32      0.28      1706\n",
      "weighted avg       0.41      0.39      0.33      1706\n",
      "\n",
      "[[ 13 159  17  47   2]\n",
      " [  9 269  15 120   5]\n",
      " [  3 136  29 161   5]\n",
      " [  1 112  19 336  17]\n",
      " [  0  31   5 170  25]]\n"
     ]
    }
   ],
   "source": [
    "tri_nb = MultinomialNB()\n",
    "tri_nb.fit(tri_features_train, train_labels)\n",
    " \n",
    "predictions = tri_nb.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','1','2','3','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 1, 2, 3, 4]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Logistische Regression\n",
    "#### 4.2.1. Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.18      0.23       238\n",
      "           1       0.36      0.43      0.39       418\n",
      "           2       0.29      0.28      0.28       334\n",
      "           3       0.42      0.47      0.44       485\n",
      "           4       0.38      0.37      0.38       231\n",
      "\n",
      "    accuracy                           0.37      1706\n",
      "   macro avg       0.36      0.34      0.35      1706\n",
      "weighted avg       0.36      0.37      0.36      1706\n",
      "\n",
      "[[ 43 115  46  29   5]\n",
      " [ 58 180  77  81  22]\n",
      " [ 12 108  92  98  24]\n",
      " [ 15  83  76 226  85]\n",
      " [  4  18  22 102  85]]\n"
     ]
    }
   ],
   "source": [
    "uni_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "uni_logreg.fit(uni_features_train, train_labels)\n",
    "#print (uni_logreg)\n",
    "\n",
    "\"\"\" default state of the classifier: \n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\"\"\"\n",
    "\n",
    "# Predictions für unseren Test-Datensatz, Accuracy, Confusion-Matrix berechnen: \n",
    "\n",
    "predictions = uni_logreg.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','1','2','3','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 1, 2, 3, 4]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Log Regression: Unigrams + Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.13      0.20       238\n",
      "           1       0.38      0.50      0.43       418\n",
      "           2       0.28      0.24      0.26       334\n",
      "           3       0.41      0.50      0.45       485\n",
      "           4       0.41      0.32      0.36       231\n",
      "\n",
      "    accuracy                           0.37      1706\n",
      "   macro avg       0.37      0.34      0.34      1706\n",
      "weighted avg       0.37      0.37      0.36      1706\n",
      "\n",
      "[[ 32 119  43  38   6]\n",
      " [ 35 210  72  83  18]\n",
      " [  9 112  80 115  18]\n",
      " [  4  97  77 241  66]\n",
      " [  3  21  17 116  74]]\n"
     ]
    }
   ],
   "source": [
    "bi_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "bi_logreg.fit(bi_features_train, train_labels)\n",
    "#print (bi_logreg)\n",
    "\n",
    "predictions = bi_logreg.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','1','2','3','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 1, 2, 3, 4]))\n",
    "# Feature-Set Größe erhöht sich weil auch Bi-Gramme berücksichtigt "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. Log Regression: Unigrams + Bigrams + Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.12      0.19       238\n",
      "           1       0.38      0.52      0.44       418\n",
      "           2       0.27      0.22      0.25       334\n",
      "           3       0.40      0.50      0.44       485\n",
      "           4       0.37      0.27      0.32       231\n",
      "\n",
      "    accuracy                           0.37      1706\n",
      "   macro avg       0.37      0.33      0.33      1706\n",
      "weighted avg       0.37      0.37      0.35      1706\n",
      "\n",
      "[[ 29 126  41  36   6]\n",
      " [ 23 219  70  90  16]\n",
      " [  8 115  75 119  17]\n",
      " [  5 100  71 242  67]\n",
      " [  2  23  19 124  63]]\n"
     ]
    }
   ],
   "source": [
    "tri_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "tri_logreg.fit(tri_features_train, train_labels)\n",
    "#print (tri_logreg)\n",
    "\n",
    "predictions = tri_logreg.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','1','2','3','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 1, 2, 3, 4]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Linear Support Vector Machine (LSVM) \n",
    "#### 4.3.1. Unigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.24      0.25       225\n",
      "           1       0.31      0.34      0.32       427\n",
      "           2       0.27      0.24      0.25       339\n",
      "           3       0.38      0.44      0.40       427\n",
      "           4       0.47      0.41      0.44       288\n",
      "\n",
      "    accuracy                           0.34      1706\n",
      "   macro avg       0.34      0.33      0.33      1706\n",
      "weighted avg       0.34      0.34      0.34      1706\n",
      "\n",
      "[[ 53 105  33  28   6]\n",
      " [ 79 145  84  95  24]\n",
      " [ 29 116  80  90  24]\n",
      " [ 29  64  72 186  76]\n",
      " [ 10  37  28  96 117]]\n"
     ]
    }
   ],
   "source": [
    "uni_lsvm = sklearn.svm.LinearSVC()\n",
    "uni_lsvm.fit(uni_features_train, train_labels)\n",
    " \n",
    "predictions = uni_lsvm.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','1','2','3','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 1, 2, 3, 4]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2. LSVM: Unigram + Bigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.21      0.27       238\n",
      "           1       0.35      0.40      0.38       418\n",
      "           2       0.28      0.28      0.28       334\n",
      "           3       0.43      0.46      0.44       485\n",
      "           4       0.36      0.39      0.37       231\n",
      "\n",
      "    accuracy                           0.37      1706\n",
      "   macro avg       0.36      0.35      0.35      1706\n",
      "weighted avg       0.36      0.37      0.36      1706\n",
      "\n",
      "[[ 51 109  42  30   6]\n",
      " [ 56 169  90  70  33]\n",
      " [ 14  97  93  98  32]\n",
      " [ 13  81  84 221  86]\n",
      " [  2  22  20  98  89]]\n"
     ]
    }
   ],
   "source": [
    "bi_lsvm = sklearn.svm.LinearSVC()\n",
    "bi_lsvm.fit(bi_features_train, train_labels)\n",
    " \n",
    "predictions = bi_lsvm.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','1','2','3','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 1, 2, 3, 4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
