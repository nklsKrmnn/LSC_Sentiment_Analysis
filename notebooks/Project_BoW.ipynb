{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_set = pd.read_csv (\"../data/datasets_mr/Trainset_complete.csv\", sep = ';')\n",
    "test_set = pd.read_csv (\"../data/datasets_mr/Testset.csv\", sep = ';')\n",
    "\n",
    "# Teilsätze rausschmeißen\n",
    "#data = data.groupby('SentenceId').first().reset_index()\n",
    "#data.head()\n",
    "\n",
    "\n",
    "# so Daten laden, wenn das test_set Sentiment Labels hätte:\n",
    "#train_set = pd.read_csv (\"train.tsv\", sep = '\\t')\n",
    "#test_set= pd.read_csv (\"test.tsv\", sep = '\\t')\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "#test_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2696\n",
       " 0    2696\n",
       " 1    2696\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.Sentiment.value_counts()\n",
    "\n",
    "# Daten ausbalancieren im Trainings-Set? \n",
    "# Jeder Sentiment Value sollte gleiche Anzahl an Samples haben "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# pip install nltk\n",
    "import re\n",
    "\n",
    "\n",
    "# Für Sentimentanalyse zählen nur Wörter  \n",
    "def keep_only_letters(text):\n",
    "    text=re.sub(r'[^a-zA-Z\\s]','',text)\n",
    "    return text\n",
    " \n",
    "# Groß- und Kleinschreibung egal \n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    " \n",
    "def clean_reviews(text):\n",
    "    text = keep_only_letters(text)\n",
    "    text = convert_to_lowercase(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Stop Words definition\n",
    "english_stop_words = nltk.corpus.stopwords.words('english')\n",
    "print(len(english_stop_words))\n",
    "print (english_stop_words[:20])\n",
    "\n",
    "# Stop Words removal\n",
    "def remove_stop_words(text):\n",
    "    for stopword in english_stop_words:\n",
    "        stopword = ' ' + stopword + ' '\n",
    "        text = text.replace(stopword, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "# Stemming\n",
    "def text_stemming(text):\n",
    "    stemmer = nltk.porter.PorterStemmer()\n",
    "    stemmed = ' '.join([stemmer.stem(token) for token in text.split()])\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_set['Phrase'] = train_set['Phrase'].apply(clean_reviews)\n",
    "# test_set['Phrase'] = test_set['Phrase'].apply(clean_reviews)\n",
    "\n",
    "train_set['Phrase'] = train_set['Phrase'].apply(remove_stop_words)\n",
    "# test_set['Phrase'] = test_set['Phrase'].apply(remove_stop_words)\n",
    "\n",
    "train_set['Phrase'] = train_set['Phrase'].apply(text_stemming) \n",
    "#test_set['Phrase'] = test_set['Phrase'].apply(text_stemming)\n",
    "\n",
    "#train_set.head(10)\n",
    "#train_set.shape\n",
    "#test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train_set, test_set = train_test_split(data, test_size=0.2)\n",
    "#train_set.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1849\n",
       "4    1849\n",
       "0    1849\n",
       "1    1849\n",
       "2    1849\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Daten balancieren\n",
    "\n",
    "\"\"\"Sentiment_groups = train_set.Sentiment.value_counts()\n",
    "for i in range(5):\n",
    "  while Sentiment_groups[i] < Sentiment_groups[3]:\n",
    "    \n",
    "    sent_i_rows = train_set.loc[train_set['Sentiment'] == i]\n",
    "    adding_row = sent_i_rows.sample()\n",
    "    train_set = train_set.append(adding_row, ignore_index=True)\n",
    "\n",
    "    Sentiment_groups = train_set.Sentiment.value_counts()\n",
    "\n",
    "train_set.Sentiment.value_counts()\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Vectorization\n",
    "CountVectorizer aus sklearn um bag-of-words Darstellung von unserem Trainings- und Testset zu erhalten\n",
    "naive bag-of-words text vectorization\n",
    "\n",
    "Nur Trainingsdatensatz zur Definition des Vokabulars heranziehen und \n",
    "das gleiche Vokabular zur Darstellung des Test-Datensatzes verwenden\n",
    "-> Vektorizer an Trainingsdaten anpassen und zur Transformation der Testdaten verwenden\n",
    "\n",
    "weighted version of BOW ausprobieren?\n",
    "\n",
    "### N-Grams\n",
    "\n",
    "Unigramme: Alle eindeutigen Wörter in einem Dokument\n",
    "\n",
    "BiGramme: Alle Permutationen von zwei aufeinanderfolgenden Wörtern in einem Dokument\n",
    "\n",
    "TriGrams: Alle Permutationen von drei aufeinanderfolgenden Wörtern in einem Dokument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# convert text data to numeric\n",
    "\n",
    "# Argument binary=False: Vocabel-Vector mit term-frequency füllen\n",
    "# binary = True: Vocabel-Vector mit Vorhandensein der Token füllen (1 vorhanden, 0 nicht vorhanden) \n",
    "# ngram _range = Unigram: (1,1); Bigram: (1,2); Trigram: (1,3)\n",
    "\n",
    "vectorizer_uni = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,1))\n",
    "vectorizer_bi = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,2))\n",
    "vectorizer_tri = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_features_train = vectorizer_uni.fit_transform(train_set['Phrase'])\n",
    "uni_features_test = vectorizer_uni.transform(test_set['Phrase'])\n",
    "#print (uni_features_train.shape, uni_features_test.shape)\n",
    "\n",
    "bi_features_train = vectorizer_bi.fit_transform(train_set['Phrase'])\n",
    "bi_features_test = vectorizer_bi.transform(test_set['Phrase'])\n",
    "#print (bi_features_train.shape, bi_features_test.shape)\n",
    "\n",
    "tri_features_train = vectorizer_tri.fit_transform(train_set['Phrase'])\n",
    "tri_features_test = vectorizer_tri.transform(test_set['Phrase'])\n",
    "#print (tri_features_train.shape, tri_features_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram:\n",
    "(156060, 10998) (66292, 10998): 10998 einzigartige englische token in unserem Vokabular (abgeleitet aus Trainingsdatensatz)\n",
    "Jeder Token wird durch eine Spalte im Datensatz repräsentiert\n",
    "Für jedes Review im Datensatz wird die Frequency der Token (term-frequency) durch Vokabel-Vector der Größe 10998 dargestellt.\n",
    "= Daher haben wir 156060 solcher Vektoren in unserem Trainings-Datensatz und 66292 in unserem Test-Datensatz = Anzahl der Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_set['Sentiment']\n",
    "test_labels = test_set['Sentiment']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Klassifizierungsmodelle trainieren\n",
    "### 4.1.  Naive Bayes\n",
    "#### 4.1.1. Unigram (Logistic Regression classifier on unigram features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.36      0.40       459\n",
      "           0       0.34      0.53      0.41       459\n",
      "           1       0.58      0.35      0.44       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.45      0.42      0.42      1377\n",
      "weighted avg       0.45      0.42      0.42      1377\n",
      "\n",
      "[[167 249  43]\n",
      " [143 243  73]\n",
      " [ 70 227 162]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    " \n",
    "vectorizer_uni = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,1))\n",
    "uni_features_train = vectorizer_uni.fit_transform(train_set['Phrase'])\n",
    "uni_features_test = vectorizer_uni.transform(test_set['Phrase'])\n",
    "\n",
    "uni_nb = MultinomialNB()\n",
    "uni_nb.fit(uni_features_train, train_labels)\n",
    " \n",
    "predictions = uni_nb.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Naive Bayes: Unigram + Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.38      0.41       459\n",
      "           0       0.34      0.49      0.40       459\n",
      "           1       0.57      0.39      0.47       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.45      0.42      0.43      1377\n",
      "weighted avg       0.45      0.42      0.43      1377\n",
      "\n",
      "[[175 237  47]\n",
      " [144 225  90]\n",
      " [ 77 201 181]]\n"
     ]
    }
   ],
   "source": [
    "#vectorizer_bi = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,2))\n",
    "#bi_features_train = vectorizer_bi.fit_transform(train_set['Phrase'])\n",
    "#bi_features_test = vectorizer_bi.transform(test_set['Phrase'])\n",
    "\n",
    "bi_nb = MultinomialNB()\n",
    "bi_nb.fit(bi_features_train, train_labels)\n",
    " \n",
    "predictions = bi_nb.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Naive Bayes: Unigram + Bigram + Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.39      0.41       459\n",
      "           0       0.34      0.48      0.40       459\n",
      "           1       0.57      0.41      0.47       459\n",
      "\n",
      "    accuracy                           0.43      1377\n",
      "   macro avg       0.45      0.43      0.43      1377\n",
      "weighted avg       0.45      0.43      0.43      1377\n",
      "\n",
      "[[178 228  53]\n",
      " [147 222  90]\n",
      " [ 77 195 187]]\n"
     ]
    }
   ],
   "source": [
    "tri_nb = MultinomialNB()\n",
    "tri_nb.fit(tri_features_train, train_labels)\n",
    " \n",
    "predictions = tri_nb.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Logistische Regression\n",
    "#### 4.2.1. Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      0.32      0.38       459\n",
      "           0       0.35      0.66      0.46       459\n",
      "           1       0.61      0.25      0.36       459\n",
      "\n",
      "    accuracy                           0.41      1377\n",
      "   macro avg       0.48      0.41      0.40      1377\n",
      "weighted avg       0.48      0.41      0.40      1377\n",
      "\n",
      "[[146 281  32]\n",
      " [114 304  41]\n",
      " [ 53 291 115]]\n"
     ]
    }
   ],
   "source": [
    "uni_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "uni_logreg.fit(uni_features_train, train_labels)\n",
    "#print (uni_logreg)\n",
    "\n",
    "\"\"\" default state of the classifier: \n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\"\"\"\n",
    "\n",
    "# Predictions für unseren Test-Datensatz, Accuracy, Confusion-Matrix berechnen: \n",
    "\n",
    "predictions = uni_logreg.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Log Regression: Unigrams + Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      0.38      0.42       459\n",
      "           0       0.37      0.61      0.46       459\n",
      "           1       0.59      0.31      0.41       459\n",
      "\n",
      "    accuracy                           0.43      1377\n",
      "   macro avg       0.47      0.43      0.43      1377\n",
      "weighted avg       0.47      0.43      0.43      1377\n",
      "\n",
      "[[175 233  51]\n",
      " [129 281  49]\n",
      " [ 69 248 142]]\n"
     ]
    }
   ],
   "source": [
    "bi_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "bi_logreg.fit(bi_features_train, train_labels)\n",
    "#print (bi_logreg)\n",
    "\n",
    "predictions = bi_logreg.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n",
    "# Feature-Set Größe erhöht sich weil auch Bi-Gramme berücksichtigt "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. Log Regression: Unigrams + Bigrams + Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.46      0.40      0.43       459\n",
      "           0       0.36      0.57      0.44       459\n",
      "           1       0.55      0.31      0.39       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.46      0.42      0.42      1377\n",
      "weighted avg       0.46      0.42      0.42      1377\n",
      "\n",
      "[[182 221  56]\n",
      " [139 261  59]\n",
      " [ 71 247 141]]\n"
     ]
    }
   ],
   "source": [
    "tri_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "tri_logreg.fit(tri_features_train, train_labels)\n",
    "#print (tri_logreg)\n",
    "\n",
    "predictions = tri_logreg.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Linear Support Vector Machine (LSVM) \n",
    "#### 4.3.1. Unigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      0.35      0.40       459\n",
      "           0       0.36      0.64      0.46       459\n",
      "           1       0.54      0.27      0.36       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.46      0.42      0.41      1377\n",
      "weighted avg       0.46      0.42      0.41      1377\n",
      "\n",
      "[[160 255  44]\n",
      " [107 293  59]\n",
      " [ 72 264 123]]\n"
     ]
    }
   ],
   "source": [
    "uni_lsvm = sklearn.svm.LinearSVC()\n",
    "uni_lsvm.fit(uni_features_train, train_labels)\n",
    " \n",
    "predictions = uni_lsvm.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2. LSVM: Unigram + Bigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.38      0.41       459\n",
      "           0       0.36      0.58      0.45       459\n",
      "           1       0.56      0.30      0.39       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.45      0.42      0.41      1377\n",
      "weighted avg       0.45      0.42      0.41      1377\n",
      "\n",
      "[[174 228  57]\n",
      " [142 266  51]\n",
      " [ 80 241 138]]\n"
     ]
    }
   ],
   "source": [
    "bi_lsvm = sklearn.svm.LinearSVC()\n",
    "bi_lsvm.fit(bi_features_train, train_labels)\n",
    " \n",
    "predictions = bi_lsvm.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3. LSVM: Unigram + Bigram + Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.46      0.38      0.42       459\n",
      "           0       0.36      0.62      0.46       459\n",
      "           1       0.55      0.26      0.35       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.46      0.42      0.41      1377\n",
      "weighted avg       0.46      0.42      0.41      1377\n",
      "\n",
      "[[176 237  46]\n",
      " [125 285  49]\n",
      " [ 82 259 118]]\n"
     ]
    }
   ],
   "source": [
    "tri_lsvm = sklearn.svm.LinearSVC()\n",
    "tri_lsvm.fit(tri_features_train, train_labels)\n",
    " \n",
    "predictions = tri_lsvm.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
