{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Bag-of-Words\n",
    "## Movie Reviews (smaller Data-Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import nltk\n",
    "import re\n",
    "import csv\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv (\"../data/datasets_mr/Trainset_complete.csv\", sep = ';')\n",
    "test_set = pd.read_csv (\"../data/datasets_mr/Testset.csv\", sep = ';')\n",
    "\n",
    "# so Daten laden, wenn das test_set Sentiment Labels hätte:\n",
    "#train_set = pd.read_csv (\"train.tsv\", sep = '\\t')\n",
    "#test_set= pd.read_csv (\"test.tsv\", sep = '\\t')\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "#test_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2696\n",
       " 0    2696\n",
       " 1    2696\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.Sentiment.value_counts()\n",
    "\n",
    "# Daten ausbalancieren im Trainings-Set? \n",
    "# Jeder Sentiment Value sollte gleiche Anzahl an Samples haben "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# pip install nltk\n",
    "import re\n",
    "\n",
    "\n",
    "# Für Sentimentanalyse zählen nur Wörter  \n",
    "def keep_only_letters(text):\n",
    "    text=re.sub(r'[^a-zA-Z\\s]','',text)\n",
    "    return text\n",
    " \n",
    "# Groß- und Kleinschreibung egal \n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    " \n",
    "def clean_reviews(text):\n",
    "    text = keep_only_letters(text)\n",
    "    text = convert_to_lowercase(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Stop Words definition\n",
    "english_stop_words = nltk.corpus.stopwords.words('english')\n",
    "print(len(english_stop_words))\n",
    "print (english_stop_words[:20])\n",
    "\n",
    "# Stop Words removal\n",
    "def remove_stop_words(text):\n",
    "    for stopword in english_stop_words:\n",
    "        stopword = ' ' + stopword + ' '\n",
    "        text = text.replace(stopword, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "# Stemming\n",
    "def text_stemming(text):\n",
    "    stemmer = nltk.porter.PorterStemmer()\n",
    "    stemmed = ' '.join([stemmer.stem(token) for token in text.split()])\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_set['Phrase'] = train_set['Phrase'].apply(clean_reviews)\n",
    "# test_set['Phrase'] = test_set['Phrase'].apply(clean_reviews)\n",
    "\n",
    "train_set['Phrase'] = train_set['Phrase'].apply(remove_stop_words)\n",
    "# test_set['Phrase'] = test_set['Phrase'].apply(remove_stop_words)\n",
    "\n",
    "train_set['Phrase'] = train_set['Phrase'].apply(text_stemming) \n",
    "#test_set['Phrase'] = test_set['Phrase'].apply(text_stemming)\n",
    "\n",
    "#train_set.head(10)\n",
    "#train_set.shape\n",
    "#test_set.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Vectorization\n",
    "CountVectorizer aus sklearn um bag-of-words Darstellung von unserem Trainings- und Testset zu erhalten\n",
    "naive bag-of-words text vectorization\n",
    "\n",
    "Nur Trainingsdatensatz zur Definition des Vokabulars heranziehen und \n",
    "das gleiche Vokabular zur Darstellung des Test-Datensatzes verwenden\n",
    "-> Vektorizer an Trainingsdaten anpassen und zur Transformation der Testdaten verwenden\n",
    "\n",
    "weighted version of BOW ausprobieren?\n",
    "\n",
    "### N-Grams\n",
    "\n",
    "Unigramme: Alle eindeutigen Wörter in einem Dokument\n",
    "\n",
    "BiGramme: Alle Permutationen von zwei aufeinanderfolgenden Wörtern in einem Dokument\n",
    "\n",
    "TriGrams: Alle Permutationen von drei aufeinanderfolgenden Wörtern in einem Dokument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# convert text data to numeric\n",
    "\n",
    "# Argument binary=False: Vocabel-Vector mit term-frequency füllen\n",
    "# binary = True: Vocabel-Vector mit Vorhandensein der Token füllen (1 vorhanden, 0 nicht vorhanden) \n",
    "# ngram _range = Unigram: (1,1); Bigram: (1,2); Trigram: (1,3)\n",
    "\n",
    "vectorizer_uni = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,1))\n",
    "vectorizer_bi = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,2))\n",
    "vectorizer_tri = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_features_train = vectorizer_uni.fit_transform(train_set['Phrase'])\n",
    "uni_features_test = vectorizer_uni.transform(test_set['Phrase'])\n",
    "#print (uni_features_train.shape, uni_features_test.shape)\n",
    "\n",
    "bi_features_train = vectorizer_bi.fit_transform(train_set['Phrase'])\n",
    "bi_features_test = vectorizer_bi.transform(test_set['Phrase'])\n",
    "#print (bi_features_train.shape, bi_features_test.shape)\n",
    "\n",
    "tri_features_train = vectorizer_tri.fit_transform(train_set['Phrase'])\n",
    "tri_features_test = vectorizer_tri.transform(test_set['Phrase'])\n",
    "#print (tri_features_train.shape, tri_features_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram:\n",
    "(156060, 10998) (66292, 10998): 10998 einzigartige englische token in unserem Vokabular (abgeleitet aus Trainingsdatensatz)\n",
    "Jeder Token wird durch eine Spalte im Datensatz repräsentiert\n",
    "Für jedes Review im Datensatz wird die Frequency der Token (term-frequency) durch Vokabel-Vector der Größe 10998 dargestellt.\n",
    "= Daher haben wir 156060 solcher Vektoren in unserem Trainings-Datensatz und 66292 in unserem Test-Datensatz = Anzahl der Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_set['Sentiment']\n",
    "test_labels = test_set['Sentiment']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Klassifizierungsmodelle trainieren\n",
    "### 4.1.  Naive Bayes\n",
    "#### 4.1.1. Unigram (Logistic Regression classifier on unigram features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.36      0.40       459\n",
      "           0       0.34      0.53      0.41       459\n",
      "           1       0.58      0.35      0.44       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.45      0.42      0.42      1377\n",
      "weighted avg       0.45      0.42      0.42      1377\n",
      "\n",
      "[[167 249  43]\n",
      " [143 243  73]\n",
      " [ 70 227 162]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    " \n",
    "vectorizer_uni = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,1))\n",
    "uni_features_train = vectorizer_uni.fit_transform(train_set['Phrase'])\n",
    "uni_features_test = vectorizer_uni.transform(test_set['Phrase'])\n",
    "\n",
    "uni_nb = MultinomialNB()\n",
    "uni_nb.fit(uni_features_train, train_labels)\n",
    " \n",
    "predictions = uni_nb.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Naive Bayes: Unigram + Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.38      0.41       459\n",
      "           0       0.34      0.49      0.40       459\n",
      "           1       0.57      0.39      0.47       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.45      0.42      0.43      1377\n",
      "weighted avg       0.45      0.42      0.43      1377\n",
      "\n",
      "[[175 237  47]\n",
      " [144 225  90]\n",
      " [ 77 201 181]]\n"
     ]
    }
   ],
   "source": [
    "#vectorizer_bi = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,2))\n",
    "#bi_features_train = vectorizer_bi.fit_transform(train_set['Phrase'])\n",
    "#bi_features_test = vectorizer_bi.transform(test_set['Phrase'])\n",
    "\n",
    "bi_nb = MultinomialNB()\n",
    "bi_nb.fit(bi_features_train, train_labels)\n",
    " \n",
    "predictions = bi_nb.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Naive Bayes: Unigram + Bigram + Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.39      0.41       459\n",
      "           0       0.34      0.48      0.40       459\n",
      "           1       0.57      0.41      0.47       459\n",
      "\n",
      "    accuracy                           0.43      1377\n",
      "   macro avg       0.45      0.43      0.43      1377\n",
      "weighted avg       0.45      0.43      0.43      1377\n",
      "\n",
      "[[178 228  53]\n",
      " [147 222  90]\n",
      " [ 77 195 187]]\n"
     ]
    }
   ],
   "source": [
    "tri_nb = MultinomialNB()\n",
    "tri_nb.fit(tri_features_train, train_labels)\n",
    " \n",
    "predictions = tri_nb.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Logistische Regression\n",
    "#### 4.2.1. Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      0.32      0.38       459\n",
      "           0       0.35      0.66      0.46       459\n",
      "           1       0.61      0.25      0.36       459\n",
      "\n",
      "    accuracy                           0.41      1377\n",
      "   macro avg       0.48      0.41      0.40      1377\n",
      "weighted avg       0.48      0.41      0.40      1377\n",
      "\n",
      "[[146 281  32]\n",
      " [114 304  41]\n",
      " [ 53 291 115]]\n"
     ]
    }
   ],
   "source": [
    "uni_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "uni_logreg.fit(uni_features_train, train_labels)\n",
    "#print (uni_logreg)\n",
    "\n",
    "\"\"\" default state of the classifier: \n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\"\"\"\n",
    "\n",
    "# Predictions für unseren Test-Datensatz, Accuracy, Confusion-Matrix berechnen: \n",
    "\n",
    "predictions = uni_logreg.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Log Regression: Unigrams + Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      0.38      0.42       459\n",
      "           0       0.37      0.61      0.46       459\n",
      "           1       0.59      0.31      0.41       459\n",
      "\n",
      "    accuracy                           0.43      1377\n",
      "   macro avg       0.47      0.43      0.43      1377\n",
      "weighted avg       0.47      0.43      0.43      1377\n",
      "\n",
      "[[175 233  51]\n",
      " [129 281  49]\n",
      " [ 69 248 142]]\n"
     ]
    }
   ],
   "source": [
    "bi_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "bi_logreg.fit(bi_features_train, train_labels)\n",
    "#print (bi_logreg)\n",
    "\n",
    "predictions = bi_logreg.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n",
    "# Feature-Set Größe erhöht sich weil auch Bi-Gramme berücksichtigt "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. Log Regression: Unigrams + Bigrams + Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.46      0.40      0.43       459\n",
      "           0       0.36      0.57      0.44       459\n",
      "           1       0.55      0.31      0.39       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.46      0.42      0.42      1377\n",
      "weighted avg       0.46      0.42      0.42      1377\n",
      "\n",
      "[[182 221  56]\n",
      " [139 261  59]\n",
      " [ 71 247 141]]\n"
     ]
    }
   ],
   "source": [
    "tri_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "tri_logreg.fit(tri_features_train, train_labels)\n",
    "#print (tri_logreg)\n",
    "\n",
    "predictions = tri_logreg.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Linear Support Vector Machine (LSVM) \n",
    "#### 4.3.1. Unigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      0.35      0.40       459\n",
      "           0       0.36      0.64      0.46       459\n",
      "           1       0.54      0.27      0.36       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.46      0.42      0.41      1377\n",
      "weighted avg       0.46      0.42      0.41      1377\n",
      "\n",
      "[[160 255  44]\n",
      " [107 293  59]\n",
      " [ 72 264 123]]\n"
     ]
    }
   ],
   "source": [
    "uni_lsvm = sklearn.svm.LinearSVC()\n",
    "uni_lsvm.fit(uni_features_train, train_labels)\n",
    " \n",
    "predictions = uni_lsvm.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2. LSVM: Unigram + Bigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.38      0.41       459\n",
      "           0       0.36      0.58      0.45       459\n",
      "           1       0.56      0.30      0.39       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.45      0.42      0.41      1377\n",
      "weighted avg       0.45      0.42      0.41      1377\n",
      "\n",
      "[[174 228  57]\n",
      " [142 266  51]\n",
      " [ 80 241 138]]\n"
     ]
    }
   ],
   "source": [
    "bi_lsvm = sklearn.svm.LinearSVC()\n",
    "bi_lsvm.fit(bi_features_train, train_labels)\n",
    " \n",
    "predictions = bi_lsvm.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3. LSVM: Unigram + Bigram + Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.46      0.38      0.42       459\n",
      "           0       0.36      0.62      0.46       459\n",
      "           1       0.55      0.26      0.35       459\n",
      "\n",
      "    accuracy                           0.42      1377\n",
      "   macro avg       0.46      0.42      0.41      1377\n",
      "weighted avg       0.46      0.42      0.41      1377\n",
      "\n",
      "[[176 237  46]\n",
      " [125 285  49]\n",
      " [ 82 259 118]]\n"
     ]
    }
   ],
   "source": [
    "tri_lsvm = sklearn.svm.LinearSVC()\n",
    "tri_lsvm.fit(tri_features_train, train_labels)\n",
    " \n",
    "predictions = tri_lsvm.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Bag-of-Words\n",
    "## Tweets (Larger Data-Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    799999\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"../data/tweets.csv\") as csvdatei:\n",
    "    data = pd.read_csv(csvdatei, delimiter=',')\n",
    "\n",
    "data.columns = ['Sentiment','ID','date','flag','user','Phrase']\n",
    "data.drop(['date','flag','user'], axis=1, inplace=True)\n",
    "data = sklearn.utils.shuffle(data)\n",
    "\n",
    "data.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# pip install nltk\n",
    "import re\n",
    "\n",
    "# Zeitbedarf: 7m 14s\n",
    "\n",
    "\n",
    "# Für Sentimentanalyse zählen nur Wörter  \n",
    "def keep_only_letters(text):\n",
    "    text=re.sub(r'[^a-zA-Z\\s]','',text)\n",
    "    return text\n",
    " \n",
    "# Groß- und Kleinschreibung egal \n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    " \n",
    "def clean_reviews(text):\n",
    "    text = keep_only_letters(text)\n",
    "    text = convert_to_lowercase(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Stop Words definition\n",
    "english_stop_words = nltk.corpus.stopwords.words('english')\n",
    "#print(len(english_stop_words))\n",
    "#print (english_stop_words[:20])\n",
    "\n",
    "# Stop Words removal\n",
    "def remove_stop_words(text):\n",
    "    for stopword in english_stop_words:\n",
    "        stopword = ' ' + stopword + ' '\n",
    "        text = text.replace(stopword, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "# Stemming\n",
    "def text_stemming(text):\n",
    "    stemmer = nltk.porter.PorterStemmer()\n",
    "    stemmed = ' '.join([stemmer.stem(token) for token in text.split()])\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#data['Phrase'] = data['Phrase'].apply(clean_reviews)\n",
    "# test_set['Phrase'] = test_set['Phrase'].apply(clean_reviews)\n",
    "\n",
    "#data['Phrase'] = data['Phrase'].apply(remove_stop_words)\n",
    "# test_set['Phrase'] = test_set['Phrase'].apply(remove_stop_words)\n",
    "\n",
    "#data['Phrase'] = data['Phrase'].apply(text_stemming) \n",
    "#test_set['Phrase'] = test_set['Phrase'].apply(text_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    640469\n",
       "0    639530\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.Sentiment.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# convert text data to numeric\n",
    "\n",
    "# Argument binary=False: Vocabel-Vector mit term-frequency füllen\n",
    "# binary = True: Vocabel-Vector mit Vorhandensein der Token füllen (1 vorhanden, 0 nicht vorhanden) \n",
    "# ngram _range = Unigram: (1,1); Bigram: (1,2); Trigram: (1,3)\n",
    "\n",
    "vectorizer_uni = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,1))\n",
    "vectorizer_bi = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,2))\n",
    "vectorizer_tri = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dauer mit Cleaning: 3m 24s \n",
    "# Dauer ohne Cleaning: 4m 46s \n",
    "\n",
    "uni_features_train = vectorizer_uni.fit_transform(train_set['Phrase'])\n",
    "uni_features_test = vectorizer_uni.transform(test_set['Phrase'])\n",
    "#print (uni_features_train.shape, uni_features_test.shape)\n",
    "\n",
    "bi_features_train = vectorizer_bi.fit_transform(train_set['Phrase'])\n",
    "bi_features_test = vectorizer_bi.transform(test_set['Phrase'])\n",
    "#print (bi_features_train.shape, bi_features_test.shape)\n",
    "\n",
    "tri_features_train = vectorizer_tri.fit_transform(train_set['Phrase'])\n",
    "tri_features_test = vectorizer_tri.transform(test_set['Phrase'])\n",
    "#print (tri_features_train.shape, tri_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_set['Sentiment']\n",
    "test_labels = test_set['Sentiment']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifizierungsmodelle trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79    160469\n",
      "           4       0.80      0.74      0.77    159531\n",
      "\n",
      "    accuracy                           0.78    320000\n",
      "   macro avg       0.78      0.78      0.78    320000\n",
      "weighted avg       0.78      0.78      0.78    320000\n",
      "\n",
      "[[131166  29303]\n",
      " [ 40827 118704]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Unigram \n",
    "# mit Cleaning: Zeit: 2s Accuracy: 0.77\n",
    "# ohne Cleaning: Zeit: 2s Accuracy: 0.78\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "uni_nb = MultinomialNB()\n",
    "uni_nb.fit(uni_features_train, train_labels)\n",
    " \n",
    "predictions = uni_nb.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81    160469\n",
      "           4       0.83      0.76      0.79    159531\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n",
      "[[135485  24984]\n",
      " [ 38642 120889]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Unigram + Bigram\n",
    "# mit Cleaning: Zeit: 6.5s Accuracy: 0.78\n",
    "# ohne Cleaning: Zeit: 6.5s Accuracy: 0.80\n",
    "\n",
    "bi_nb = MultinomialNB()\n",
    "bi_nb.fit(bi_features_train, train_labels)\n",
    " \n",
    "predictions = bi_nb.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81    160469\n",
      "           4       0.83      0.76      0.79    159531\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.81      0.80      0.80    320000\n",
      "weighted avg       0.81      0.80      0.80    320000\n",
      "\n",
      "[[136124  24345]\n",
      " [ 38513 121018]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Unigram + Bigram + Trigram\n",
    "# mit Cleaning: Zeit: 4.2s Accuracy: 0.79\n",
    "# mit Cleaning: Zeit: 4.2s Accuracy: 0.80\n",
    "\n",
    "tri_nb = MultinomialNB()\n",
    "tri_nb.fit(tri_features_train, train_labels)\n",
    " \n",
    "predictions = tri_nb.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80    160469\n",
      "           4       0.79      0.81      0.80    159531\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n",
      "[[126367  34102]\n",
      " [ 30165 129366]]\n"
     ]
    }
   ],
   "source": [
    "# Logistische Regression Unigram\n",
    "# mit Cleaning: Zeit: 5m 50s Accuracy: 0.78\n",
    "# ohne Cleaning: Zeit: 7m 26s Accuracy: 0.80\n",
    "\n",
    "\n",
    "uni_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "uni_logreg.fit(uni_features_train, train_labels)\n",
    "\n",
    "predictions = uni_logreg.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80    159839\n",
      "           4       0.79      0.82      0.80    160161\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n",
      "[[124923  34916]\n",
      " [ 29087 131074]]\n"
     ]
    }
   ],
   "source": [
    "# Logistische Regression Unigram + Bigram\n",
    "# mit Cleaning: Zeit: 20m 7s Accuracy: 0.80 \n",
    "\n",
    "\n",
    "bi_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "bi_logreg.fit(bi_features_train, train_labels)\n",
    "#print (bi_logreg)\n",
    "\n",
    "predictions = bi_logreg.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))\n",
    "# Feature-Set Größe erhöht sich weil auch Bi-Gramme berücksichtigt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80    159839\n",
      "           4       0.79      0.82      0.81    160161\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n",
      "[[125228  34611]\n",
      " [ 28664 131497]]\n"
     ]
    }
   ],
   "source": [
    "# Logistische Regression Unigram + Bigram + Trigram\n",
    "# mit Cleaning: Zeit: 36m 21s Accuracy: 0.80 \n",
    "\n",
    "tri_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "tri_logreg.fit(tri_features_train, train_labels)\n",
    "#print (tri_logreg)\n",
    "\n",
    "predictions = tri_logreg.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77    159839\n",
      "           4       0.77      0.77      0.77    160161\n",
      "\n",
      "    accuracy                           0.77    320000\n",
      "   macro avg       0.77      0.77      0.77    320000\n",
      "weighted avg       0.77      0.77      0.77    320000\n",
      "\n",
      "[[122554  37285]\n",
      " [ 36412 123749]]\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Machine (LSVM) Unigram\n",
    "# mit Cleaning: Zeit: 10m 12s Accuracy: 0.77 \n",
    "\n",
    "uni_lsvm = sklearn.svm.LinearSVC()\n",
    "uni_lsvm.fit(uni_features_train, train_labels)\n",
    " \n",
    "predictions = uni_lsvm.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78    159839\n",
      "           4       0.78      0.79      0.79    160161\n",
      "\n",
      "    accuracy                           0.79    320000\n",
      "   macro avg       0.79      0.78      0.78    320000\n",
      "weighted avg       0.79      0.79      0.78    320000\n",
      "\n",
      "[[123915  35924]\n",
      " [ 32874 127287]]\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Machine (LSVM) Unigram + Bigram\n",
    "# mit Cleaning: Zeit: 11m 30s Accuracy: 0.79 \n",
    "\n",
    "bi_lsvm = sklearn.svm.LinearSVC()\n",
    "bi_lsvm.fit(bi_features_train, train_labels)\n",
    " \n",
    "predictions = bi_lsvm.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79    159839\n",
      "           4       0.79      0.80      0.80    160161\n",
      "\n",
      "    accuracy                           0.79    320000\n",
      "   macro avg       0.79      0.79      0.79    320000\n",
      "weighted avg       0.79      0.79      0.79    320000\n",
      "\n",
      "[[124800  35039]\n",
      " [ 31339 128822]]\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Machine (LSVM) Unigram + Bigram + Trigram\n",
    "# mit Cleaning: Zeit: 13m 10s Accuracy: 0.79\n",
    "\n",
    "tri_lsvm = sklearn.svm.LinearSVC()\n",
    "tri_lsvm.fit(tri_features_train, train_labels)\n",
    " \n",
    "predictions = tri_lsvm.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
