{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd '/content/drive/MyDrive/LSC_Sentiment_Analysis'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTGCSTQ1SgyH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688818192372,
     "user_tz": -120,
     "elapsed": 16045,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    },
    "outputId": "71c6443c-ed39-4f57-dae8-7ff76f9c9ff2"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/.shortcut-targets-by-id/1iBSu5iMtGl5Ys7feuwPxbrIUCugIipJf/LSC_Sentiment_Analysis\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-6bP6nfSaMm"
   },
   "source": [
    "# Sentiment Analysis Bag-of-Words\n",
    "## Movie Reviews (smaller Data-Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1BjtDvn4SaMp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1688818197077,
     "user_tz": -120,
     "elapsed": 4706,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "from evaluation import test_statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHDQgzX9SaMq"
   },
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unyHZzN0SaMr",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995392,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv (\"../data/datasets_mr/Trainset_complete.csv\", sep = ';')\n",
    "test_set = pd.read_csv (\"../data/datasets_mr/Testset.csv\", sep = ';')\n",
    "\n",
    "# so Daten laden, wenn das test_set Sentiment Labels hätte:\n",
    "#train_set = pd.read_csv (\"train.tsv\", sep = '\\t')\n",
    "#test_set= pd.read_csv (\"test.tsv\", sep = '\\t')\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "#test_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tbfBPhCSaMr",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995392,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "train_set.Sentiment.value_counts()\n",
    "\n",
    "# Daten ausbalancieren im Trainings-Set?\n",
    "# Jeder Sentiment Value sollte gleiche Anzahl an Samples haben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z010GGNwSaMs"
   },
   "source": [
    "## 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SguWNB6qSaMs",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995392,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# pip install nltk\n",
    "import re\n",
    "\n",
    "\n",
    "# Für Sentimentanalyse zählen nur Wörter\n",
    "def keep_only_letters(text):\n",
    "    text=re.sub(r'[^a-zA-Z\\s]','',text)\n",
    "    return text\n",
    "\n",
    "# Groß- und Kleinschreibung egal\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def clean_reviews(text):\n",
    "    text = keep_only_letters(text)\n",
    "    text = convert_to_lowercase(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Stop Words definition\n",
    "english_stop_words = nltk.corpus.stopwords.words('english')\n",
    "print(len(english_stop_words))\n",
    "print (english_stop_words[:20])\n",
    "\n",
    "# Stop Words removal\n",
    "def remove_stop_words(text):\n",
    "    for stopword in english_stop_words:\n",
    "        stopword = ' ' + stopword + ' '\n",
    "        text = text.replace(stopword, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "# Stemming\n",
    "def text_stemming(text):\n",
    "    stemmer = nltk.porter.PorterStemmer()\n",
    "    stemmed = ' '.join([stemmer.stem(token) for token in text.split()])\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_set['Phrase'] = train_set['Phrase'].apply(clean_reviews)\n",
    "# test_set['Phrase'] = test_set['Phrase'].apply(clean_reviews)\n",
    "\n",
    "train_set['Phrase'] = train_set['Phrase'].apply(remove_stop_words)\n",
    "# test_set['Phrase'] = test_set['Phrase'].apply(remove_stop_words)\n",
    "\n",
    "train_set['Phrase'] = train_set['Phrase'].apply(text_stemming)\n",
    "#test_set['Phrase'] = test_set['Phrase'].apply(text_stemming)\n",
    "\n",
    "#train_set.head(10)\n",
    "#train_set.shape\n",
    "#test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZs2J6kLSaMs"
   },
   "source": [
    "## 3. Text Vectorization\n",
    "CountVectorizer aus sklearn um bag-of-words Darstellung von unserem Trainings- und Testset zu erhalten\n",
    "naive bag-of-words text vectorization\n",
    "\n",
    "Nur Trainingsdatensatz zur Definition des Vokabulars heranziehen und\n",
    "das gleiche Vokabular zur Darstellung des Test-Datensatzes verwenden\n",
    "-> Vektorizer an Trainingsdaten anpassen und zur Transformation der Testdaten verwenden\n",
    "\n",
    "weighted version of BOW ausprobieren?\n",
    "\n",
    "### N-Grams\n",
    "\n",
    "Unigramme: Alle eindeutigen Wörter in einem Dokument\n",
    "\n",
    "BiGramme: Alle Permutationen von zwei aufeinanderfolgenden Wörtern in einem Dokument\n",
    "\n",
    "TriGrams: Alle Permutationen von drei aufeinanderfolgenden Wörtern in einem Dokument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGyCm6GUSaMt",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995393,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# convert text data to numeric\n",
    "\n",
    "# Argument binary=False: Vocabel-Vector mit term-frequency füllen\n",
    "# binary = True: Vocabel-Vector mit Vorhandensein der Token füllen (1 vorhanden, 0 nicht vorhanden)\n",
    "# ngram _range = Unigram: (1,1); Bigram: (1,2); Trigram: (1,3)\n",
    "\n",
    "vectorizer_uni = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,1))\n",
    "vectorizer_bi = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,2))\n",
    "vectorizer_tri = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6uoxSNuSaMt",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995393,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "uni_features_train = vectorizer_uni.fit_transform(train_set['Phrase'])\n",
    "uni_features_test = vectorizer_uni.transform(test_set['Phrase'])\n",
    "#print (uni_features_train.shape, uni_features_test.shape)\n",
    "\n",
    "bi_features_train = vectorizer_bi.fit_transform(train_set['Phrase'])\n",
    "bi_features_test = vectorizer_bi.transform(test_set['Phrase'])\n",
    "#print (bi_features_train.shape, bi_features_test.shape)\n",
    "\n",
    "tri_features_train = vectorizer_tri.fit_transform(train_set['Phrase'])\n",
    "tri_features_test = vectorizer_tri.transform(test_set['Phrase'])\n",
    "#print (tri_features_train.shape, tri_features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaYgO2yGSaMt"
   },
   "source": [
    "Unigram:\n",
    "(156060, 10998) (66292, 10998): 10998 einzigartige englische token in unserem Vokabular (abgeleitet aus Trainingsdatensatz)\n",
    "Jeder Token wird durch eine Spalte im Datensatz repräsentiert\n",
    "Für jedes Review im Datensatz wird die Frequency der Token (term-frequency) durch Vokabel-Vector der Größe 10998 dargestellt.\n",
    "= Daher haben wir 156060 solcher Vektoren in unserem Trainings-Datensatz und 66292 in unserem Test-Datensatz = Anzahl der Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcWQyIMOSaMt",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995393,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "train_labels = train_set['Sentiment']\n",
    "test_labels = test_set['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMAGUTE0SaMt"
   },
   "source": [
    "## 4. Klassifizierungsmodelle trainieren\n",
    "### 4.1.  Naive Bayes\n",
    "#### 4.1.1. Unigram (Logistic Regression classifier on unigram features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GO8UY4yVSaMu",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995394,
     "user_tz": -120,
     "elapsed": 7,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer_uni = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,1))\n",
    "uni_features_train = vectorizer_uni.fit_transform(train_set['Phrase'])\n",
    "uni_features_test = vectorizer_uni.transform(test_set['Phrase'])\n",
    "\n",
    "uni_nb = MultinomialNB()\n",
    "uni_nb.fit(uni_features_train, train_labels)\n",
    "\n",
    "predictions = uni_nb.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTGliPFrSaMu"
   },
   "source": [
    "#### 4.1.2 Naive Bayes: Unigram + Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cP1qpesASaMu",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995394,
     "user_tz": -120,
     "elapsed": 7,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "#vectorizer_bi = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,2))\n",
    "#bi_features_train = vectorizer_bi.fit_transform(train_set['Phrase'])\n",
    "#bi_features_test = vectorizer_bi.transform(test_set['Phrase'])\n",
    "\n",
    "bi_nb = MultinomialNB()\n",
    "bi_nb.fit(bi_features_train, train_labels)\n",
    "\n",
    "predictions = bi_nb.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2lOZcCGSaMu"
   },
   "source": [
    "#### 4.1.3 Naive Bayes: Unigram + Bigram + Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pR0NrIt3SaMu",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995394,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "tri_nb = MultinomialNB()\n",
    "tri_nb.fit(tri_features_train, train_labels)\n",
    "\n",
    "predictions = tri_nb.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4LNr3pGSaMu"
   },
   "source": [
    "### 4.2 Logistische Regression\n",
    "#### 4.2.1. Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdHH1mILSaMv",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995394,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "uni_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "uni_logreg.fit(uni_features_train, train_labels)\n",
    "#print (uni_logreg)\n",
    "\n",
    "\"\"\" default state of the classifier:\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\"\"\"\n",
    "\n",
    "# Predictions für unseren Test-Datensatz, Accuracy, Confusion-Matrix berechnen:\n",
    "\n",
    "predictions = uni_logreg.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvZEvQkpSaMv"
   },
   "source": [
    "#### 4.2.2. Log Regression: Unigrams + Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWv_e4AVSaMv",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995394,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "bi_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "bi_logreg.fit(bi_features_train, train_labels)\n",
    "#print (bi_logreg)\n",
    "\n",
    "predictions = bi_logreg.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))\n",
    "# Feature-Set Größe erhöht sich weil auch Bi-Gramme berücksichtigt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwRv0acISaMv"
   },
   "source": [
    "#### 4.2.3. Log Regression: Unigrams + Bigrams + Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrGWH1R9SaMv",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995395,
     "user_tz": -120,
     "elapsed": 7,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "tri_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "tri_logreg.fit(tri_features_train, train_labels)\n",
    "#print (tri_logreg)\n",
    "\n",
    "predictions = tri_logreg.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4-KXvnWSaMv"
   },
   "source": [
    "### 4.3 Linear Support Vector Machine (LSVM)\n",
    "#### 4.3.1. Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W26ced9FSaMw",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995395,
     "user_tz": -120,
     "elapsed": 7,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "uni_lsvm = sklearn.svm.LinearSVC()\n",
    "uni_lsvm.fit(uni_features_train, train_labels)\n",
    "\n",
    "predictions = uni_lsvm.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yD5w0oN3SaMw"
   },
   "source": [
    "#### 4.3.2. LSVM: Unigram + Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiETmq09SaMw",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995395,
     "user_tz": -120,
     "elapsed": 16447,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "bi_lsvm = sklearn.svm.LinearSVC()\n",
    "bi_lsvm.fit(bi_features_train, train_labels)\n",
    "\n",
    "predictions = bi_lsvm.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "678rDKMmSaMw"
   },
   "source": [
    "#### 4.3.3. LSVM: Unigram + Bigram + Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKfREgB5SaMw",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995395,
     "user_tz": -120,
     "elapsed": 16444,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "tri_lsvm = sklearn.svm.LinearSVC()\n",
    "tri_lsvm.fit(tri_features_train, train_labels)\n",
    "\n",
    "predictions = tri_lsvm.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['-1','0','1']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUpApqbiSaMw"
   },
   "source": [
    "# Sentiment Analysis Bag-of-Words\n",
    "## Tweets (Larger Data-Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8IdyDbXSaMw",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995396,
     "user_tz": -120,
     "elapsed": 16441,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"../data/tweets.csv\") as csvdatei:\n",
    "    data = pd.read_csv(csvdatei, delimiter=',')\n",
    "\n",
    "data.columns = ['Sentiment','ID','date','flag','user','Phrase']\n",
    "data.drop(['date','flag','user'], axis=1, inplace=True)\n",
    "data = sklearn.utils.shuffle(data)\n",
    "\n",
    "data.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlsE_oyqSaMx",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995396,
     "user_tz": -120,
     "elapsed": 16440,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# pip install nltk\n",
    "import re\n",
    "\n",
    "# Zeitbedarf: 7m 14s\n",
    "\n",
    "\n",
    "# Für Sentimentanalyse zählen nur Wörter\n",
    "def keep_only_letters(text):\n",
    "    text=re.sub(r'[^a-zA-Z\\s]','',text)\n",
    "    return text\n",
    "\n",
    "# Groß- und Kleinschreibung egal\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def clean_reviews(text):\n",
    "    text = keep_only_letters(text)\n",
    "    text = convert_to_lowercase(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Stop Words definition\n",
    "english_stop_words = nltk.corpus.stopwords.words('english')\n",
    "#print(len(english_stop_words))\n",
    "#print (english_stop_words[:20])\n",
    "\n",
    "# Stop Words removal\n",
    "def remove_stop_words(text):\n",
    "    for stopword in english_stop_words:\n",
    "        stopword = ' ' + stopword + ' '\n",
    "        text = text.replace(stopword, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "# Stemming\n",
    "def text_stemming(text):\n",
    "    stemmer = nltk.porter.PorterStemmer()\n",
    "    stemmed = ' '.join([stemmer.stem(token) for token in text.split()])\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#data['Phrase'] = data['Phrase'].apply(clean_reviews)\n",
    "# test_set['Phrase'] = test_set['Phrase'].apply(clean_reviews)\n",
    "\n",
    "#data['Phrase'] = data['Phrase'].apply(remove_stop_words)\n",
    "# test_set['Phrase'] = test_set['Phrase'].apply(remove_stop_words)\n",
    "\n",
    "#data['Phrase'] = data['Phrase'].apply(text_stemming)\n",
    "#test_set['Phrase'] = test_set['Phrase'].apply(text_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjEupWnJSaMx",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995396,
     "user_tz": -120,
     "elapsed": 16439,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJQVlhCaSaMx",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995396,
     "user_tz": -120,
     "elapsed": 16435,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "train_set.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ka3zqoeFSaMx"
   },
   "source": [
    "## 3. Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDKbgL4LSaMx",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995396,
     "user_tz": -120,
     "elapsed": 16434,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# convert text data to numeric\n",
    "\n",
    "# Argument binary=False: Vocabel-Vector mit term-frequency füllen\n",
    "# binary = True: Vocabel-Vector mit Vorhandensein der Token füllen (1 vorhanden, 0 nicht vorhanden)\n",
    "# ngram _range = Unigram: (1,1); Bigram: (1,2); Trigram: (1,3)\n",
    "\n",
    "vectorizer_uni = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,1))\n",
    "vectorizer_bi = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,2))\n",
    "vectorizer_tri = sklearn.feature_extraction.text.CountVectorizer(binary=False,ngram_range=(1,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ak6d4GslSaMx",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995396,
     "user_tz": -120,
     "elapsed": 16433,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Dauer mit Cleaning: 3m 24s\n",
    "# Dauer ohne Cleaning: 4m 46s\n",
    "\n",
    "uni_features_train = vectorizer_uni.fit_transform(train_set['Phrase'])\n",
    "uni_features_test = vectorizer_uni.transform(test_set['Phrase'])\n",
    "#print (uni_features_train.shape, uni_features_test.shape)\n",
    "\n",
    "bi_features_train = vectorizer_bi.fit_transform(train_set['Phrase'])\n",
    "bi_features_test = vectorizer_bi.transform(test_set['Phrase'])\n",
    "#print (bi_features_train.shape, bi_features_test.shape)\n",
    "\n",
    "tri_features_train = vectorizer_tri.fit_transform(train_set['Phrase'])\n",
    "tri_features_test = vectorizer_tri.transform(test_set['Phrase'])\n",
    "#print (tri_features_train.shape, tri_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbsF3V4RSaMx",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995397,
     "user_tz": -120,
     "elapsed": 16433,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "train_labels = train_set['Sentiment']\n",
    "test_labels = test_set['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrhBEvjBSaMy"
   },
   "source": [
    "## Klassifizierungsmodelle trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUDQo9EgSaMy",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995397,
     "user_tz": -120,
     "elapsed": 16430,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Unigram\n",
    "# mit Cleaning: Zeit: 2s Accuracy: 0.77\n",
    "# ohne Cleaning: Zeit: 2s Accuracy: 0.78\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "uni_nb = MultinomialNB()\n",
    "uni_nb.fit(uni_features_train, train_labels)\n",
    "\n",
    "predictions = uni_nb.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24DEuukHSaMy",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995398,
     "user_tz": -120,
     "elapsed": 16427,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Unigram + Bigram\n",
    "# mit Cleaning: Zeit: 6.5s Accuracy: 0.78\n",
    "# ohne Cleaning: Zeit: 6.5s Accuracy: 0.80\n",
    "\n",
    "bi_nb = MultinomialNB()\n",
    "bi_nb.fit(bi_features_train, train_labels)\n",
    "\n",
    "predictions = bi_nb.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXi7MgIKSaMy",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995398,
     "user_tz": -120,
     "elapsed": 16423,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Unigram + Bigram + Trigram\n",
    "# mit Cleaning: Zeit: 4.2s Accuracy: 0.79\n",
    "# mit Cleaning: Zeit: 4.2s Accuracy: 0.80\n",
    "\n",
    "tri_nb = MultinomialNB()\n",
    "tri_nb.fit(tri_features_train, train_labels)\n",
    "\n",
    "predictions = tri_nb.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9KOfTumSaMz",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995398,
     "user_tz": -120,
     "elapsed": 16420,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Logistische Regression Unigram\n",
    "# mit Cleaning: Zeit: 5m 50s Accuracy: 0.78\n",
    "# ohne Cleaning: Zeit: 7m 26s Accuracy: 0.80\n",
    "\n",
    "\n",
    "uni_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "uni_logreg.fit(uni_features_train, train_labels)\n",
    "\n",
    "predictions = uni_logreg.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5iaenrQSaMz",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995399,
     "user_tz": -120,
     "elapsed": 16417,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Logistische Regression Unigram + Bigram\n",
    "# mit Cleaning: Zeit: 20m 7s Accuracy: 0.80\n",
    "\n",
    "\n",
    "bi_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "bi_logreg.fit(bi_features_train, train_labels)\n",
    "#print (bi_logreg)\n",
    "\n",
    "predictions = bi_logreg.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))\n",
    "# Feature-Set Größe erhöht sich weil auch Bi-Gramme berücksichtigt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9mj5yztSaMz",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995399,
     "user_tz": -120,
     "elapsed": 16413,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Logistische Regression Unigram + Bigram + Trigram\n",
    "# mit Cleaning: Zeit: 36m 21s Accuracy: 0.80\n",
    "\n",
    "tri_logreg = sklearn.linear_model.LogisticRegression(max_iter=10000)\n",
    "tri_logreg.fit(tri_features_train, train_labels)\n",
    "#print (tri_logreg)\n",
    "\n",
    "predictions = tri_logreg.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klxKmmSPSaMz",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995399,
     "user_tz": -120,
     "elapsed": 16410,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Linear Support Vector Machine (LSVM) Unigram\n",
    "# mit Cleaning: Zeit: 10m 12s Accuracy: 0.77\n",
    "\n",
    "uni_lsvm = sklearn.svm.LinearSVC()\n",
    "uni_lsvm.fit(uni_features_train, train_labels)\n",
    "\n",
    "predictions = uni_lsvm.predict(uni_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPXTUdHRSaMz",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995399,
     "user_tz": -120,
     "elapsed": 16406,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Linear Support Vector Machine (LSVM) Unigram + Bigram\n",
    "# mit Cleaning: Zeit: 11m 30s Accuracy: 0.79\n",
    "\n",
    "bi_lsvm = sklearn.svm.LinearSVC()\n",
    "bi_lsvm.fit(bi_features_train, train_labels)\n",
    "\n",
    "predictions = bi_lsvm.predict(bi_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-zJ5oNxSaM0",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1688817995399,
     "user_tz": -120,
     "elapsed": 16403,
     "user": {
      "displayName": "h aesff",
      "userId": "04495051921663497128"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Linear Support Vector Machine (LSVM) Unigram + Bigram + Trigram\n",
    "# mit Cleaning: Zeit: 13m 10s Accuracy: 0.79\n",
    "\n",
    "tri_lsvm = sklearn.svm.LinearSVC()\n",
    "tri_lsvm.fit(tri_features_train, train_labels)\n",
    "\n",
    "predictions = tri_lsvm.predict(tri_features_test)\n",
    "print(sklearn.metrics.classification_report(test_labels, predictions, target_names=['0','4']))\n",
    "print(sklearn.metrics.confusion_matrix(test_labels, predictions, labels=[0, 4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
